{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff20f6e",
   "metadata": {},
   "source": [
    "# Core Question Process\n",
    "What are the overall trends in sales?\n",
    " --> This starts very broad, so we need to iteratively clarify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b46269",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "READ Framework for framing the project before querying anything\n",
    "\n",
    "R - Representative Data: \n",
    "    do we have the right data to answer this? \n",
    "We don't have order dates or revenue so we can't see change over calendar periods or true sales volume beyond quantities. We have day of the week, reoder information, even time of day so we can see trends in those areas via order/product counts. \n",
    "\n",
    "E - Exec questions: \n",
    "    transformation from vague to business-relevant\n",
    "Metric clarifications: what are we measuring? \n",
    "    Before: What are the overall trends in sales?\n",
    "    After: How did total order volume and reorder rate change?\n",
    "Dimension: how do we slice it? \n",
    "    Department, time of day, day of the week.\n",
    "    We can remove time of day for now. \n",
    "Deliverable: for whom, in what format? \n",
    "    Marketing and operations management would likely find insights useful. \n",
    "Clarified question: How do total order volume and reorder rate change across departments and between weekdays and weekends? .\n",
    "\n",
    "A - Analytical Framework: \n",
    "    Time series - time of day and day of week\n",
    "    Segmentation by department\n",
    "\n",
    "D - Data best practices: \n",
    "    Check for nulls, odd ranges\n",
    "\n",
    "\n",
    "After all this, we have data that may be able to help Marketing & Ops understand order behavior across departments across different days of the week and hours of the day, and modify their strategies accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98bd856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   null_id  null_user  null_eval  null_num  null_dow  null_hour  min_hour  \\\n",
      "0      0.0        0.0        0.0       0.0       0.0        0.0         0   \n",
      "\n",
      "   max_hour  \n",
      "0        23  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import duckdb\n",
    "con = duckdb.connect(\"instacart.duckdb\")\n",
    "\n",
    "df_user_orders = con.execute(\"\"\"\n",
    "    SELECT \n",
    "    SUM(order_id IS NULL) AS null_id,\n",
    "    SUM(user_id IS NULL) AS null_user,\n",
    "    SUM(eval_set IS NULL) AS null_eval,\n",
    "    SUM(order_number IS NULL) AS null_num,\n",
    "    SUM(order_dow IS NULL) AS null_dow,\n",
    "    SUM(order_hour_of_day IS NULL) AS null_hour,\n",
    "    -- SUM(days_since_prior_order IS NULL) AS null_days_since, -> not counting because this represents the number of first time orders\n",
    "    MIN(CAST(order_hour_of_day AS INT)) AS min_hour,\n",
    "    MAX(CAST(order_hour_of_day AS INT)) AS max_hour\n",
    "    FROM orders;\n",
    "\"\"\").fetchdf()\n",
    "print(df_user_orders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2755bee",
   "metadata": {},
   "source": [
    "Data is well-cleaned, mostly IDs and integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a544ff",
   "metadata": {},
   "source": [
    "### Part 2: Mapping goals to data features\n",
    "\n",
    "Stakeholder Goals  | what KPIs and dimensions matter the most? \n",
    "    When are we selling - what can we do to take advantage of that and what can we do to make up for the less efficient times? \n",
    "\n",
    "Columns and Coverage  | what data do we have available and how can I use it?   \n",
    "    Volume of items per department per hour of individual days\n",
    "    \n",
    "Aggregates and Anomalies  | the high level metrics, outliers, and unexpected patterns  \n",
    "| Metric | Why it Matters | Quick SQL |\n",
    "| :- | :- | :- |\n",
    "| Total orders | Anchor everything else | SELECT COUNT(*) AS n_orders FROM orders; \n",
    "| Avg items per order | Spot exceptionally large baskets later | sql WITH line_ct AS (SELECT order_id, COUNT(*) AS n_items FROM order_products_train GROUP BY order_id) SELECT AVG(n_items) FROM line_ct;\n",
    "| Overall reorder‑rate | Acts as “global mean” for dept/aisle compare | SELECT AVG(reordered)::DOUBLE AS reorder_rate FROM order_products_train;\n",
    "\n",
    "Notable Segments  | slice by category, time, or other key dimensions to surface early insights \n",
    "    See aggregates by key dimensions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f31fb5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_hour_of_day  orders\n",
      "0                 00   22758\n",
      "1                 01   12398\n",
      "2                 02    7539\n",
      "3                 03    5474\n",
      "4                 04    5527\n",
      "5                 05    9569\n",
      "6                 06   30529\n",
      "7                 07   91868\n",
      "8                 08  178201\n",
      "9                 09  257812\n",
      "10                10  288418\n",
      "11                11  284728\n",
      "12                12  272841\n",
      "13                13  277999\n",
      "14                14  283042\n",
      "15                15  283639\n",
      "16                16  272553\n",
      "17                17  228795\n",
      "18                18  182912\n",
      "19                19  140569\n",
      "20                20  104292\n",
      "21                21   78109\n",
      "22                22   61468\n",
      "23                23   40043\n",
      "   total         avg   min     max\n",
      "0     24  142545.125  5474  288418\n"
     ]
    }
   ],
   "source": [
    "# Orders by hour of day\n",
    "orders_by_hour = con.execute(\"\"\"\n",
    "    SELECT \n",
    "    order_hour_of_day,\n",
    "    COUNT(*) AS orders\n",
    "    FROM orders\n",
    "    group by order_hour_of_day\n",
    "    order by order_hour_of_day;\n",
    "\"\"\").fetchdf()\n",
    "print(orders_by_hour)\n",
    "\n",
    "orders_by_hour_insights = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) as total,\n",
    "        AVG(orders) as avg,\n",
    "        MIN(orders) as min,\n",
    "        MAX(orders) as max\n",
    "    FROM\n",
    "        (SELECT \n",
    "        order_hour_of_day,\n",
    "        COUNT(*) AS orders\n",
    "        FROM orders\n",
    "        group by order_hour_of_day\n",
    "        order by order_hour_of_day) AS orders_per_hour;\n",
    "\"\"\").fetchdf()\n",
    "print(orders_by_hour_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8768e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sunday  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday\n",
      "0  600905  587478   467260     436972    426339  453368    448761\n"
     ]
    }
   ],
   "source": [
    "# Orders by day of week\n",
    "orders_by_day = con.execute(\"\"\"\n",
    "    SELECT \n",
    "    COUNT(CASE WHEN order_dow = 0 Then 1 END) AS Sunday,\n",
    "    COUNT(CASE WHEN order_dow = 1 Then 1 END) AS Monday,\n",
    "    COUNT(CASE WHEN order_dow = 2 Then 1 END) AS Tuesday,\n",
    "    COUNT(CASE WHEN order_dow = 3 Then 1 END) AS Wednesday,\n",
    "    COUNT(CASE WHEN order_dow = 4 Then 1 END) AS Thursday,\n",
    "    COUNT(CASE WHEN order_dow = 5 Then 1 END) AS Friday,\n",
    "    COUNT(CASE WHEN order_dow = 6 Then 1 END) AS Saturday,\n",
    "    FROM orders\n",
    "    ;\n",
    "\"\"\").fetchdf()\n",
    "print(orders_by_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a322e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         department  product_count  reorder_rate\n",
      "0           produce         409087      0.664617\n",
      "1        dairy eggs         217051      0.674966\n",
      "2            snacks         118862      0.581363\n",
      "3         beverages         114046      0.658155\n",
      "4            frozen         100426      0.559297\n",
      "5            pantry          81242      0.363088\n",
      "6            bakery          48394      0.634211\n",
      "7      canned goods          46799      0.486805\n",
      "8              deli          44291      0.617891\n",
      "9   dry goods pasta          38713      0.487821\n",
      "10        household          35986      0.427166\n",
      "11     meat seafood          30307      0.590854\n",
      "12        breakfast          29500      0.571661\n",
      "13    personal care          21570      0.337089\n",
      "14           babies          14941      0.541062\n",
      "15    international          11902      0.379936\n",
      "16          missing           8251      0.381530\n",
      "17          alcohol           5598      0.606824\n",
      "18             pets           4497      0.630198\n",
      "19            other           1795      0.388301\n",
      "20             bulk           1359      0.578366\n"
     ]
    }
   ],
   "source": [
    "# Product volume & reorder‑rate by department\n",
    "\n",
    "department_volume = con.execute(\"\"\"\n",
    "    SELECT                \n",
    "        d.department,\n",
    "        COUNT(*) as product_count,\n",
    "        AVG(opt.reordered) as reorder_rate\n",
    "    FROM order_products_train opt\n",
    "    JOIN products p on opt.product_id = p.product_id\n",
    "    JOIN departments d on d.department_id = p.department_id\n",
    "    GROUP BY 1\n",
    "    ORDER BY 2 DESC\n",
    "    ;\n",
    "\"\"\").fetchdf()\n",
    "print(department_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ae066b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   totals  seventy_plus  sixty_to_seventy  fifty_to_sixty  forty_to_fifty  \\\n",
      "0  131209            14                31             148             650   \n",
      "\n",
      "   thirty_to_forty  twenty_to_thirty  ten_to_twenty  under_ten    average  \\\n",
      "0             3066             12632          42860      71808  10.552759   \n",
      "\n",
      "   min  max  \n",
      "0    1   80  \n"
     ]
    }
   ],
   "source": [
    "# Items per order insights \n",
    "\n",
    "order_items = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total orders,\n",
    "        COUNT(CASE WHEN item_count >= 70 THEN 1 END) AS seventy_plus,\n",
    "        COUNT(CASE WHEN item_count >= 60 AND item_count < 70 THEN 1 END) AS sixty_to_seventy,\n",
    "        COUNT(CASE WHEN item_count >= 50 AND item_count < 60 THEN 1 END) AS fifty_to_sixty,\n",
    "        COUNT(CASE WHEN item_count >= 40 AND item_count < 50 THEN 1 END) AS forty_to_fifty,\n",
    "        COUNT(CASE WHEN item_count >= 30 AND item_count < 40 THEN 1 END) AS thirty_to_forty,\n",
    "        COUNT(CASE WHEN item_count >= 20 AND item_count < 30 THEN 1 END) AS twenty_to_thirty,\n",
    "        COUNT(CASE WHEN item_count >= 10 AND item_count < 20 THEN 1 END) AS ten_to_twenty,\n",
    "        COUNT(CASE WHEN item_count < 10 THEN 1 END) AS under_ten,             \n",
    "        AVG(item_count) as average,\n",
    "        Min(item_count) as min,\n",
    "        Max(item_count) as max\n",
    "    FROM \n",
    "        (SELECT\n",
    "        order_id,\n",
    "        COUNT(*) AS item_count\n",
    "        FROM order_products_train\n",
    "        GROUP BY order_id) AS item_counts\n",
    "    ;\n",
    "\"\"\").fetchdf()\n",
    "print(order_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5d66a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     order_id  item_count  order_dow order_hour_of_day\n",
      "0     1016866          57          4                16\n",
      "1     2232869          50          1                15\n",
      "2     2823840          61          3                13\n",
      "3     1100193          55          5                16\n",
      "4      319031          52          2                13\n",
      "..        ...         ...        ...               ...\n",
      "188   2658620          50          3                03\n",
      "189   1997174          53          6                11\n",
      "190    690200          53          5                12\n",
      "191   2803519          52          6                11\n",
      "192    653280          72          0                21\n",
      "\n",
      "[193 rows x 4 columns]\n",
      "   order_dow  dow_counts\n",
      "0          0          41\n",
      "1          1          33\n",
      "2          2          24\n",
      "3          3          23\n",
      "4          4          19\n",
      "5          5          25\n",
      "6          6          28\n",
      "   order_hour_of_day  hod_counts\n",
      "0                 12          11\n",
      "1                 22           7\n",
      "2                 07           7\n",
      "3                 19           7\n",
      "4                 00           1\n",
      "5                 16          17\n",
      "6                 17          16\n",
      "7                 21           8\n",
      "8                 15          11\n",
      "9                 06           1\n",
      "10                04           2\n",
      "11                14          22\n",
      "12                23           3\n",
      "13                18           6\n",
      "14                10          15\n",
      "15                01           2\n",
      "16                08           5\n",
      "17                03           1\n",
      "18                11          15\n",
      "19                13          22\n",
      "20                20           4\n",
      "21                09          10\n"
     ]
    }
   ],
   "source": [
    "# Any significance in when the larger orders are happening? Anything above 50 items\n",
    "\n",
    "order_items = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        item_counts_outliers.order_id,\n",
    "        item_counts_outliers.item_count,\n",
    "        o.order_dow,\n",
    "        o.order_hour_of_day\n",
    "    FROM\n",
    "        (SELECT\n",
    "            opt.order_id,\n",
    "            COUNT(*) AS item_count, \n",
    "        FROM order_products_train opt\n",
    "        GROUP BY opt.order_id\n",
    "        HAVING item_count >= 50) \n",
    "    AS item_counts_outliers\n",
    "    JOIN orders o on item_counts_outliers.order_id = o.order_id\n",
    "    ;\n",
    "\"\"\").fetchdf()\n",
    "print(order_items)\n",
    "\n",
    "order_items = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        order_dow,\n",
    "        COUNT(*) AS dow_counts\n",
    "    FROM\n",
    "        (SELECT \n",
    "            item_counts_outliers.order_id,\n",
    "            item_counts_outliers.item_count,\n",
    "            o.order_dow,\n",
    "            o.order_hour_of_day\n",
    "        FROM\n",
    "            (SELECT\n",
    "                opt.order_id,\n",
    "                COUNT(*) AS item_count, \n",
    "            FROM order_products_train opt\n",
    "            GROUP BY opt.order_id\n",
    "            HAVING item_count >= 50) \n",
    "        AS item_counts_outliers\n",
    "        JOIN orders o on item_counts_outliers.order_id = o.order_id) AS c\n",
    "    GROUP BY order_dow\n",
    "    ;\n",
    "\"\"\").fetchdf()\n",
    "print(order_items)\n",
    "\n",
    "order_items = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        order_hour_of_day,\n",
    "        COUNT(*) AS hod_counts\n",
    "    FROM\n",
    "        (SELECT \n",
    "            item_counts_outliers.order_id,\n",
    "            item_counts_outliers.item_count,\n",
    "            o.order_dow,\n",
    "            o.order_hour_of_day\n",
    "        FROM\n",
    "            (SELECT\n",
    "                opt.order_id,\n",
    "                COUNT(*) AS item_count, \n",
    "            FROM order_products_train opt\n",
    "            GROUP BY opt.order_id\n",
    "            HAVING item_count >= 50) \n",
    "        AS item_counts_outliers\n",
    "        JOIN orders o on item_counts_outliers.order_id = o.order_id) AS c\n",
    "    GROUP BY order_hour_of_day\n",
    "    ;\n",
    "\"\"\").fetchdf()\n",
    "print(order_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f3867",
   "metadata": {},
   "source": [
    "Compare outlier hod and dow counts in proportion to totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df3dad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_dow_name  outlier_orders  total_orders  outlier_rate\n",
      "0         SUNDAY              41         27465        0.0015\n",
      "1         MONDAY              33         19672        0.0017\n",
      "2        TUESDAY              24         16119        0.0015\n",
      "3      WEDNESDAY              23         15687        0.0015\n",
      "4       THURSDAY              19         15959        0.0012\n",
      "5         FRIDAY              25         17406        0.0014\n",
      "6       SATURDAY              28         18901        0.0015\n"
     ]
    }
   ],
   "source": [
    "# compare orders by day of week to outliers - larger proportions on any days? \n",
    "\n",
    "order_items = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        CASE WHEN order_dow = 0 THEN 'SUNDAY'\n",
    "            WHEN order_dow = 1 THEN 'MONDAY'\n",
    "            WHEN order_dow = 2 THEN 'TUESDAY'\n",
    "            WHEN order_dow = 3 THEN 'WEDNESDAY'\n",
    "            WHEN order_dow = 4 THEN 'THURSDAY'\n",
    "            WHEN order_dow = 5 THEN 'FRIDAY'\n",
    "            WHEN order_dow = 6 THEN 'SATURDAY'\n",
    "        END AS  order_dow_name,\n",
    "        SUM(is_outlier)::INT AS outlier_orders,\n",
    "        COUNT(*) AS total_orders,\n",
    "        ROUND(SUM(is_outlier)/COUNT(*),4) AS outlier_rate\n",
    "    FROM \n",
    "        (SELECT\n",
    "            o.order_dow,\n",
    "            CASE WHEN ic.item_count >= 50 THEN 1 ELSE 0 END AS is_outlier\n",
    "        FROM (\n",
    "            SELECT\n",
    "                opt.order_id,\n",
    "                COUNT(*) AS item_count \n",
    "            FROM order_products_train AS opt\n",
    "            GROUP BY opt.order_id) \n",
    "        as ic\n",
    "        JOIN orders o  ON ic.order_id = o.order_id) AS labeled_orders\n",
    "    GROUP BY order_dow\n",
    "    ORDER BY order_dow;\n",
    "\"\"\").fetchdf()\n",
    "print(order_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0199201",
   "metadata": {},
   "source": [
    "Slightly higher outlier rates on Monday, slightly lower on Thursday, but no surprises or significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d99078",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "### 1. Peak ordering happens late morning to midafternoon\n",
    "Users probably place orders when meal planning, perhaps when getting ready to return from work or while thinking about lunch. Promos and staffing should follow this curve. Incentives to make sure there are enough shoppers on hand. \n",
    "Schedule notifications and ads soon before and throughout the 10AM-3pm window. \n",
    "\n",
    "### 2. Sunday is most popular day\n",
    "Weekend uptick in demand is real and makes sense, but Saturday significantly underperforming Sunday could indicate room for improvement via targeting Saturdays. \n",
    "\n",
    "### 3. Most carts are very small (<10 items)\n",
    "We can call it most users being in \"top-up\" mode, just getting a few necessities. \n",
    "Over 50% of orders are <10 items. Average, even with outliers up to 80 items, is just over 10 items per cart. \n",
    "Significant cross-sell opportunity with correct product placement and 1-click adds. \n",
    "\n",
    "### 4. Departmental differences seem to reflect normal consumer habits\n",
    "Higher reorder rates in deli, produce, alcohol, etc. make sense. Lower reorder rates in personal care/household COULD indicate stocking issues but are also in line with expectations for that kind of product. Fresh produce is needed every week. Household items likely not. No significant concern, but worth investigating potential for upping reorders in less popular depts. \n",
    "\n",
    "### 5. Large orders cluster in later afternoon. \n",
    "Orders over 50 items are less than 0.05%, but they are usually between 4-7pm. \n",
    "Small businesses stocking up late could make up a lot of this business - could explore opportunities for partnerships there. \n",
    "\n",
    "## Specific Insights Table\n",
    "| Metric / Dimension | Finding | Team |\n",
    "| :- | :- | :- |\n",
    "| Hour of Day | Orders peak 10-15hr, 2 stdev above mean at peak | Ops/Marketing |\n",
    "| Day of Week | Sunday highest, Tues-Thurs lowest | Ops/Marketing | \n",
    "| Department reorder rates | Produce / deli / alcohol higher than global reoder rate, personal care and home low | Product, ops |\n",
    "| Cart size disstribution | 55%+ <10 items, avg 10.6, long tail to 80 max | ops, growth(?) |\n",
    "| Order size by hour | few orders over 50 items, but they are clustered in late afternoon 16-19hr | Operations | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
